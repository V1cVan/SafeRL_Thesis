CRITICAL:root:Model Parameters:
CRITICAL:root:{'n_units': (64, 32, 18), 'n_inputs': 54, 'n_actions': 5, 'activation_function': <function swish at 0x0000020407123048>, 'weights_file_path': './models/model_weights', 'seed': 3156612391}
CRITICAL:root:Training param:
CRITICAL:root:{'max_timesteps': 2500.0, 'max_episodes': 5000, 'final_return': 0.9, 'show_train_plots': False, 'plot_freq': 50, 'sim_timesteps': 200, 'buffer_size': 1000000, 'batch_size': 100, 'epsilon_max': 0.1, 'epsilon_min': 1.0, 'decay_rate': 0.999997, 'model_update_rate': 1, 'target_update_rate': 100000.0, 'policy_rate': 8, 'gamma': 0.99, 'clip_gradients': True, 'clip_norm': 2, 'learning_rate': 0.0003, 'optimiser': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000002040C3BCD88>, 'loss_func': <tensorflow.python.keras.losses.Huber object at 0x000002040ADA49C8>, 'seed': 3156612391, 'standardise_returns': True, 'reward_weights': array([ 1.  ,  0.2 ,  0.8 ,  0.35, -5.  ]), 'use_per': False, 'alpha': 0.75, 'beta': 0.2, 'beta_increment': 0.001, 'use_duelling': True}
CRITICAL:root:Episode number: 1.00
CRITICAL:root:Running reward = 0.03 (0.61) at episode 1. Loss = 0.01. Epsilon = 1.00.
CRITICAL:root:Episode number: 2.00
